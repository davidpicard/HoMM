defaults:
  - train_batch_preprocess: null
  - network: hlm
  - loss: CE
  - optimizer: adamw
  - lr_scheduler: warmup_cosine_decay

name: HLM
instance:
  _target_: model.llm.LLMModule
  model: ${model.network}
  loss: ${model.loss}
  optimizer_cfg: ${model.optimizer}
  lr_scheduler_builder: ${model.lr_scheduler}
  torch_compile: false

